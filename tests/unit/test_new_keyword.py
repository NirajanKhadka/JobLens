#!/usr/bin/env python3
"""
Test script with a new keyword to verify extraction improvements.
"""

import sys
import os
from src.utils.profile_helpers import load_profile, get_available_profiles
from src.utils.job_helpers import generate_job_hash, is_duplicate_job, sort_jobs
from src.utils.file_operations import save_jobs_to_json, load_jobs_from_json, save_jobs_to_csv
from src.utils.document_generator import customize, DocumentGenerator
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rich.console import Console
from rich.panel import Panel
from src.core.job_database import get_job_db


console = Console()

def test_new_keyword():
    """Test extraction with a new keyword to avoid duplicates."""
    
    console.print(Panel("üß™ Testing New Keyword Extraction", style="bold cyan"))
    
    try:
        # Load profile
        profile = load_profile('Nirajan')
        if not profile:
            console.print("[red]‚ùå Could not load Nirajan profile[/red]")
            return False
            
        console.print(f"[green]‚úÖ Loaded profile: {profile['profile_name']}[/green]")
        
        # Get initial database stats
        db = get_job_db(profile['profile_name'])
        initial_stats = db.get_stats()
        console.print(f"[cyan]üìä Initial database stats: {initial_stats['total_jobs']} jobs[/cyan]")
        
        # Test scraping with a new keyword to avoid duplicates
        console.print("[cyan]üîç Testing with new keyword 'Business Analyst'...[/cyan]")
        
        from src.scrapers.eluta_enhanced import ElutaEnhancedScraper
        from playwright.sync_api import sync_playwright
        
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=False)
            context = browser.new_context()
            
            # Create scraper with new keyword
            test_profile = profile.copy()
            test_profile["keywords"] = ["Business Analyst"]  # New keyword
            
            scraper = ElutaEnhancedScraper(test_profile, browser_context=context, deep_scraping=False)
            scraper.max_pages_per_keyword = 1  # Just test 1 page
            
            console.print("[cyan]üöÄ Starting test scraping with new keyword...[/cyan]")
            jobs = list(scraper.scrape_jobs())
            browser.close()
        
        console.print(f"[green]‚úÖ Scraping complete! Found {len(jobs)} jobs[/green]")
        
        if jobs:
            # Show sample jobs
            console.print("[cyan]üìã Sample extracted jobs:[/cyan]")
            for i, job in enumerate(jobs[:5], 1):
                console.print(f"  {i}. {job['title']} at {job['company']}")
                console.print(f"     URL: {job['url'][:60]}...")
            
            # Save jobs to database
            console.print(f"[cyan]üíæ Saving {len(jobs)} jobs to database...[/cyan]")
            saved_count = 0
            duplicate_count = 0
            
            for job in jobs:
                if db.add_job(job):
                    saved_count += 1
                else:
                    duplicate_count += 1
            
            console.print(f"[green]üíæ Saved {saved_count} new jobs to database ({duplicate_count} duplicates skipped)[/green]")
            
            # Get final database stats
            final_stats = db.get_stats()
            console.print(f"[cyan]üìä Final database stats: {final_stats['total_jobs']} jobs[/cyan]")
            
            # Calculate improvement
            jobs_added = final_stats['total_jobs'] - initial_stats['total_jobs']
            console.print(f"[bold green]üéâ Successfully added {jobs_added} new jobs to database![/bold green]")
            
            return True
        else:
            console.print("[yellow]‚ö†Ô∏è No jobs were extracted[/yellow]")
            return False
            
    except Exception as e:
        console.print(f"[red]‚ùå Error during test: {e}[/red]")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_new_keyword()
