{
  "ai_service": {
    "primary_model": "llama3:7b",
    "endpoint": "http://localhost:11434",
    "timeout": 30,
    "max_retries": 3,
    "fallback_to_rule_based": true
  },
  "processing": {
    "batch_size": 10,
    "concurrent_jobs": 3,
    "enable_ai_analysis": true,
    "enable_document_generation": true
  }
}